import cv2
import mediapipe as mp
import numpy as np
import pyautogui
import time
pyautogui.FAILSAFE = False
# Define constants
wCam, hCam = 640, 480
frameR = 60  # Reduce frame reduction for more precise hand tracking
smoothening = 30  # Increased smoothening for smoother cursor movement
click_threshold = 50  # Distance threshold for clicks
scale_factor = 0.1  # Scaling factor to reduce mouse movement

# Initialize libraries
mpHands = mp.solutions.hands
hands = mpHands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5)
mpDraw = mp.solutions.drawing_utils

# Get screen resolution
screen_width, screen_height = pyautogui.size()


def findHands(img, draw=True):
    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = hands.process(imgRGB)

    if results.multi_hand_landmarks:
        for handLms in results.multi_hand_landmarks:
            if draw:
                mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)

    return img, results


def findPosition(img, results, handNo=0):
    lmList = []
    if results is not None and results.multi_hand_landmarks:
        myHand = results.multi_hand_landmarks[handNo]
        for id, lm in enumerate(myHand.landmark):
            h, w, c = img.shape
            cx, cy = int(lm.x * w), int(lm.y * h)
            lmList.append([id, cx, cy])

    return lmList


def calculateDistance(p1, p2):
    x1, y1 = p1
    x2, y2 = p2
    return np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)


def main():
    pTime = 0
    clocX, clocY = 0, 0
    plocX, plocY = 0, 0

    cap = cv2.VideoCapture(0)
    cap.set(3, wCam)
    cap.set(4, hCam)

    while True:
        success, img = cap.read()

        # Find hands and landmarks
        img, results = findHands(img)
        lmList = findPosition(img, results)

        # Check for hand detection
        if len(lmList) != 0:
            # Get index and thumb tip coordinates
            indexTip = lmList[8]
            thumbTip = lmList[4]

            # Calculate distance between index and thumb
            distance = calculateDistance(indexTip[1:], thumbTip[1:])

            # Click detection
            if distance < click_threshold:
                cv2.circle(img, (indexTip[1], indexTip[2]), 15, (0, 255, 0), cv2.FILLED)
                pyautogui.click()

            # Convert hand coordinates to screen coordinates with smoothing and scaling
            x3 = np.interp(indexTip[1], (frameR, wCam - frameR), (0, screen_width*3))
            y3 = np.interp(indexTip[2], (frameR, hCam - frameR), (0, screen_height*3))
            x3 /= scale_factor
            y3 /= scale_factor
            clocX = plocX + (x3 - plocX) / smoothening
            clocY = plocY + (y3 - plocY) / smoothening

            # Move mouse cursor
            pyautogui.moveTo(clocX, clocY)

            # Draw circle on index fingertip
            cv2.circle(img, (indexTip[1], indexTip[2]), 15, (255, 0, 255), cv2.FILLED)

        # Calculate FPS
        cTime = time.time()
        fps = 1 / (cTime - pTime)
        pTime = cTime
        cv2.putText(img, str(int(fps)), (20, 50), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 3)

        # Display image
        cv2.imshow("Virtual Mouse", img)
        if cv2.waitKey(1) == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
